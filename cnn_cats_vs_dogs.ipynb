{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Building the CNN\n",
    "import keras\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialiing the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: pooling\n",
    "classifier.add(MaxPooling2D(pool_size= (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding another convolutional layer to imoprove the accuracy\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size= (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: flattening\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: full connection\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dropout(0.6))\n",
    "classifier.add(Dense(units=64, activation='relu'))\n",
    "classifier.add(Dropout(0.3))\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 821,409\n",
      "Trainable params: 821,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit CNN to images\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = training_datagen.flow_from_directory('dataset/training_set/', \n",
    "                                                    target_size=(64,64), \n",
    "                                                    batch_size=32, \n",
    "                                                    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = testing_datagen.flow_from_directory('dataset/test_set/', \n",
    "                                                target_size=(64,64), \n",
    "                                                batch_size=32, \n",
    "                                                class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 83s 332ms/step - loss: 0.6783 - acc: 0.5740 - val_loss: 0.6583 - val_acc: 0.6220\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 93s 373ms/step - loss: 0.6337 - acc: 0.6538 - val_loss: 0.5982 - val_acc: 0.6835\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 91s 363ms/step - loss: 0.5987 - acc: 0.6829 - val_loss: 0.5801 - val_acc: 0.6970\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 88s 352ms/step - loss: 0.5790 - acc: 0.6939 - val_loss: 0.5446 - val_acc: 0.7365\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 84s 338ms/step - loss: 0.5634 - acc: 0.7115 - val_loss: 0.5179 - val_acc: 0.7420\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 83s 333ms/step - loss: 0.5495 - acc: 0.7155 - val_loss: 0.5422 - val_acc: 0.7205\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 84s 335ms/step - loss: 0.5384 - acc: 0.7308 - val_loss: 0.5010 - val_acc: 0.7575\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 86s 343ms/step - loss: 0.5166 - acc: 0.7454 - val_loss: 0.4911 - val_acc: 0.7560\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 85s 342ms/step - loss: 0.5129 - acc: 0.7509 - val_loss: 0.4944 - val_acc: 0.7580\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 89s 354ms/step - loss: 0.4991 - acc: 0.7626 - val_loss: 0.4849 - val_acc: 0.7645\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 89s 355ms/step - loss: 0.4875 - acc: 0.7654 - val_loss: 0.4721 - val_acc: 0.7755\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 91s 366ms/step - loss: 0.4762 - acc: 0.7732 - val_loss: 0.4989 - val_acc: 0.7690\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 119s 474ms/step - loss: 0.4798 - acc: 0.7756 - val_loss: 0.4583 - val_acc: 0.7890\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 152s 607ms/step - loss: 0.4681 - acc: 0.7798 - val_loss: 0.4689 - val_acc: 0.7635\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 156s 622ms/step - loss: 0.4587 - acc: 0.7814 - val_loss: 0.4561 - val_acc: 0.7880\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 169s 677ms/step - loss: 0.4583 - acc: 0.7839 - val_loss: 0.4576 - val_acc: 0.7890\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 95s 382ms/step - loss: 0.4487 - acc: 0.7899 - val_loss: 0.4711 - val_acc: 0.7735\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 80s 318ms/step - loss: 0.4300 - acc: 0.7986 - val_loss: 0.4379 - val_acc: 0.7940\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 76s 304ms/step - loss: 0.4293 - acc: 0.7989 - val_loss: 0.4496 - val_acc: 0.7835\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 77s 307ms/step - loss: 0.4191 - acc: 0.8100 - val_loss: 0.4331 - val_acc: 0.7945\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 73s 293ms/step - loss: 0.4214 - acc: 0.8076 - val_loss: 0.4330 - val_acc: 0.8065\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 72s 289ms/step - loss: 0.4155 - acc: 0.8139 - val_loss: 0.4357 - val_acc: 0.7920\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 73s 294ms/step - loss: 0.4096 - acc: 0.8140 - val_loss: 0.4308 - val_acc: 0.8090\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 74s 298ms/step - loss: 0.4092 - acc: 0.8156 - val_loss: 0.4352 - val_acc: 0.7955\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 73s 291ms/step - loss: 0.3976 - acc: 0.8223 - val_loss: 0.4821 - val_acc: 0.7850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x120bba780>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set, \n",
    "                         steps_per_epoch=8000/32, \n",
    "                         epochs=25, \n",
    "                         validation_data=test_set, \n",
    "                         validation_steps=2000/32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
